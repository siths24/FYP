{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1266bb-c4d9-43a4-9021-1bc974d3e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Download complete. File saved as: Stravl_Travel_Preference_Data.csv\n",
      "Preview of the dataset:\n",
      "                                 id      form_a form_b form_c  \\\n",
      "0  22871c2cb8ee11ec9a19fefb5d5b7ead  ['0', '1']  ['1']  ['2']   \n",
      "1  89b7022ab8f011ec9a19fefb5d5b7ead  ['0', '1']  ['3']  ['2']   \n",
      "2  c64f6c36b8f011ec9a19fefb5d5b7ead       ['1']  ['1']  ['2']   \n",
      "3  1eb6079ab8f111ec9a19fefb5d5b7ead       ['1']  ['1']  ['2']   \n",
      "4  285e9852b8f111ec9a19fefb5d5b7ead       ['1']  ['0']  ['1']   \n",
      "\n",
      "                           form_f                form_g form_h form_i form_j  \\\n",
      "0            ['0', '1', '2', '7']       ['0', '2', '4']  ['1']  ['1']  ['1']   \n",
      "1  ['0', '3', '4', '5', '6', '7']  ['0', '1', '2', '4']  ['1']  ['1']  ['1']   \n",
      "2       ['0', '1', '3', '4', '7']  ['0', '2', '4', '7']  ['1']  ['1']  ['1']   \n",
      "3                           ['7']                 ['4']  ['1']  ['2']  ['1']   \n",
      "4                           ['2']       ['2', '3', '4']  ['0']  ['1']  ['0']   \n",
      "\n",
      "  form_k  ... Rec_0 Rec_1 Rec_2 Rec_3 Rec_4  Rec_5  Rec_6  Rec_7  Rec_8  Rec_9  \n",
      "0  ['2']  ...    -1    -1    -1    -1    -1     -1     -1     -1     -1     -1  \n",
      "1  ['1']  ...    -1    -1    -1    -1    -1     -1     -1     -1     -1     -1  \n",
      "2  ['0']  ...    -1    -1    -1    -1    -1     -1     -1     -1     -1     -1  \n",
      "3  ['1']  ...    -1    -1    -1    -1    -1     -1     -1     -1     -1     -1  \n",
      "4  ['0']  ...    -1    -1    -1    -1    -1     -1     -1     -1     -1     -1  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "#define the correct URL for the raw CSV file\n",
    "csv_url = \"https://raw.githubusercontent.com/Stravl/Stravl-Data/main/Stravl_Travel_Preference_Data.csv\"\n",
    "csv_file_path = \"Stravl_Travel_Preference_Data.csv\"\n",
    "\n",
    "#download the CSV file\n",
    "print(\"Downloading dataset...\")\n",
    "urllib.request.urlretrieve(csv_url, csv_file_path)\n",
    "print(f\"Download complete. File saved as: {csv_file_path}\")\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "print(\"Preview of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dffd792-db19-4592-987a-6701e4bf49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#destination file\n",
    "url = \"https://raw.githubusercontent.com/Stravl/Stravl-Data/main/destination_ids.txt\"\n",
    "\n",
    "#fetch the file content\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  \n",
    "\n",
    "#load the destination mappings\n",
    "destination_mapping = {i: line.strip() for i, line in enumerate(response.text.splitlines())}\n",
    "\n",
    "# # Load destination mappings\n",
    "# destination_file = r\"C:\\Users\\sithu\\OneDrive\\Desktop\\Stravl-Data-main\\destination_ids.txt\"\n",
    "# with open(destination_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#     destination_mapping = {i: line.strip() for i, line in enumerate(f.readlines())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90865d74-6037-4afe-aac0-3a8bfef849c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding completed.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "#decode swipe data\n",
    "def decode_swipes(swipe_data):\n",
    "    if pd.isna(swipe_data) or swipe_data == \"[]\":\n",
    "        return []\n",
    "    indices = ast.literal_eval(swipe_data)\n",
    "    return [destination_mapping.get(i, f\"Unknown({i})\") for i in indices]\n",
    "\n",
    "df['yes_swipes'] = df['yes_swipes'].apply(decode_swipes)\n",
    "df['no_swipes'] = df['no_swipes'].apply(decode_swipes)\n",
    "df['maybe_swipes'] = df['maybe_swipes'].apply(decode_swipes)\n",
    "\n",
    "print(\"Decoding completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a9d2fa-905a-4cd8-b0c2-402bf37920c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'form_a', 'form_b', 'form_c', 'form_f', 'form_g', 'form_h',\n",
      "       'form_i', 'form_j', 'form_k', 'form_r', 'form_rr', 'yes_swipes',\n",
      "       'no_swipes', 'maybe_swipes', 'Model', 'Retrieval', 'DynaMatch',\n",
      "       'Rating_0', 'Rating_1', 'Rating_2', 'Rating_3', 'Rating_4', 'Rating_5',\n",
      "       'Rating_6', 'Rating_7', 'Rating_8', 'Rating_9', 'Rec_0', 'Rec_1',\n",
      "       'Rec_2', 'Rec_3', 'Rec_4', 'Rec_5', 'Rec_6', 'Rec_7', 'Rec_8', 'Rec_9'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6a153bf-d58f-48ab-949f-4cb868086f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id                form_a  \\\n",
      "0      22871c2cb8ee11ec9a19fefb5d5b7ead            ['0', '1']   \n",
      "1      89b7022ab8f011ec9a19fefb5d5b7ead            ['0', '1']   \n",
      "2      c64f6c36b8f011ec9a19fefb5d5b7ead                 ['1']   \n",
      "3      1eb6079ab8f111ec9a19fefb5d5b7ead                 ['1']   \n",
      "4      285e9852b8f111ec9a19fefb5d5b7ead                 ['1']   \n",
      "...                                 ...                   ...   \n",
      "80296  61b5e56ed28211edadc00e96bc2eb5a0  ['0', '1', '2', '3']   \n",
      "80297  259dade6d28211edb561563501293886  ['0', '1', '2', '3']   \n",
      "80298  53a67fecd28211ed8ef3560e516905ce  ['0', '1', '2', '3']   \n",
      "80299  5e9fea64d28211ed8ef3560e516905ce  ['0', '1', '2', '3']   \n",
      "80300  7315bb72d28211ed8ef3560e516905ce  ['0', '1', '2', '3']   \n",
      "\n",
      "                     form_b form_c                          form_f  \\\n",
      "0                     ['1']  ['2']            ['0', '1', '2', '7']   \n",
      "1                     ['3']  ['2']  ['0', '3', '4', '5', '6', '7']   \n",
      "2                     ['1']  ['2']       ['0', '1', '3', '4', '7']   \n",
      "3                     ['1']  ['2']                           ['7']   \n",
      "4                     ['0']  ['1']                           ['2']   \n",
      "...                     ...    ...                             ...   \n",
      "80296  ['0', '1', '2', '3']  ['1']                           ['7']   \n",
      "80297  ['0', '1', '2', '3']  ['0']                 ['1', '2', '4']   \n",
      "80298  ['0', '1', '2', '3']  ['0']                 ['0', '1', '2']   \n",
      "80299  ['0', '1', '2', '3']  ['2']            ['3', '5', '6', '7']   \n",
      "80300  ['0', '1', '2', '3']  ['1']                           ['0']   \n",
      "\n",
      "                     form_g form_h form_i           form_j form_k  ...  \\\n",
      "0           ['0', '2', '4']  ['1']  ['1']            ['1']  ['2']  ...   \n",
      "1      ['0', '1', '2', '4']  ['1']  ['1']            ['1']  ['1']  ...   \n",
      "2      ['0', '2', '4', '7']  ['1']  ['1']            ['1']  ['0']  ...   \n",
      "3                     ['4']  ['1']  ['2']            ['1']  ['1']  ...   \n",
      "4           ['2', '3', '4']  ['0']  ['1']            ['0']  ['0']  ...   \n",
      "...                     ...    ...    ...              ...    ...  ...   \n",
      "80296  ['0', '2', '3', '7']  ['1']  ['1']  ['0', '1', '2']  ['1']  ...   \n",
      "80297       ['1', '3', '4']  ['1']  ['1']  ['0', '1', '2']  ['1']  ...   \n",
      "80298            ['1', '2']  ['2']  ['2']  ['0', '1', '2']  ['1']  ...   \n",
      "80299       ['0', '3', '5']  ['1']  ['1']  ['0', '1', '2']  ['1']  ...   \n",
      "80300                 ['2']  ['1']  ['1']  ['0', '1', '2']  ['1']  ...   \n",
      "\n",
      "                  form_a_decoded                       form_b_decoded  \\\n",
      "0                  [0-19, 20-39]                            [$50-$99]   \n",
      "1                  [0-19, 20-39]                              [$300+]   \n",
      "2                        [20-39]                            [$50-$99]   \n",
      "3                        [20-39]                            [$50-$99]   \n",
      "4                        [20-39]                             [$0-$49]   \n",
      "...                          ...                                  ...   \n",
      "80296  [0-19, 20-39, 40-59, 60+]  [$0-$49, $50-$99, $100-$249, $300+]   \n",
      "80297  [0-19, 20-39, 40-59, 60+]  [$0-$49, $50-$99, $100-$249, $300+]   \n",
      "80298  [0-19, 20-39, 40-59, 60+]  [$0-$49, $50-$99, $100-$249, $300+]   \n",
      "80299  [0-19, 20-39, 40-59, 60+]  [$0-$49, $50-$99, $100-$249, $300+]   \n",
      "80300  [0-19, 20-39, 40-59, 60+]  [$0-$49, $50-$99, $100-$249, $300+]   \n",
      "\n",
      "      form_c_decoded                                     form_f_decoded  \\\n",
      "0           [Summer]                [Beach, Adventure, Nature, Cuisine]   \n",
      "1           [Summer]  [Beach, Culture, Nightlife, History, Shopping,...   \n",
      "2           [Summer]    [Beach, Adventure, Culture, Nightlife, Cuisine]   \n",
      "3           [Summer]                                          [Cuisine]   \n",
      "4           [Spring]                                           [Nature]   \n",
      "...              ...                                                ...   \n",
      "80296       [Spring]                                          [Cuisine]   \n",
      "80297       [Winter]                     [Adventure, Nature, Nightlife]   \n",
      "80298       [Winter]                         [Beach, Adventure, Nature]   \n",
      "80299       [Summer]              [Culture, History, Shopping, Cuisine]   \n",
      "80300       [Spring]                                            [Beach]   \n",
      "\n",
      "                       form_g_decoded     form_h_decoded  \\\n",
      "0                  [Urban, Sea, Lake]         [Balanced]   \n",
      "1           [Urban, Rural, Sea, Lake]         [Balanced]   \n",
      "2          [Urban, Sea, Lake, Jungle]         [Balanced]   \n",
      "3                              [Lake]         [Balanced]   \n",
      "4               [Sea, Mountain, Lake]  [Chill & Relaxed]   \n",
      "...                               ...                ...   \n",
      "80296  [Urban, Sea, Mountain, Jungle]         [Balanced]   \n",
      "80297         [Rural, Mountain, Lake]         [Balanced]   \n",
      "80298                    [Rural, Sea]           [Active]   \n",
      "80299       [Urban, Mountain, Desert]         [Balanced]   \n",
      "80300                           [Sea]         [Balanced]   \n",
      "\n",
      "             form_i_decoded  \\\n",
      "0                [Balanced]   \n",
      "1                [Balanced]   \n",
      "2                [Balanced]   \n",
      "3      [Ready for Anything]   \n",
      "4                [Balanced]   \n",
      "...                     ...   \n",
      "80296            [Balanced]   \n",
      "80297            [Balanced]   \n",
      "80298  [Ready for Anything]   \n",
      "80299            [Balanced]   \n",
      "80300            [Balanced]   \n",
      "\n",
      "                                          form_j_decoded      form_r_decoded  \\\n",
      "0                                         [Classic Spot]                None   \n",
      "1                                         [Classic Spot]                None   \n",
      "2                                         [Classic Spot]                None   \n",
      "3                                         [Classic Spot]                None   \n",
      "4                                  [Off the Beaten Path]                None   \n",
      "...                                                  ...                 ...   \n",
      "80296  [Off the Beaten Path, Classic Spot, Mainstream...          [Anywhere]   \n",
      "80297  [Off the Beaten Path, Classic Spot, Mainstream...  [Specific Regions]   \n",
      "80298  [Off the Beaten Path, Classic Spot, Mainstream...  [Specific Regions]   \n",
      "80299  [Off the Beaten Path, Classic Spot, Mainstream...  [Specific Regions]   \n",
      "80300  [Off the Beaten Path, Classic Spot, Mainstream...  [Specific Regions]   \n",
      "\n",
      "                                      form_rr_decoded  \n",
      "0                                                None  \n",
      "1                                                None  \n",
      "2                                                None  \n",
      "3                                                None  \n",
      "4                                                None  \n",
      "...                                               ...  \n",
      "80296                                            None  \n",
      "80297                      [Europe, N. America, Asia]  \n",
      "80298  [Europe, N. America, Caribbean, Asia, Oceania]  \n",
      "80299                                    [N. America]  \n",
      "80300                                    [N. America]  \n",
      "\n",
      "[80301 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "#form mappings\n",
    "form_mappings = {\n",
    "    \"form_a\": {0: \"0-19\", 1: \"20-39\", 2: \"40-59\", 3: \"60+\"},\n",
    "    \"form_b\": {0: \"$0-$49\", 1: \"$50-$99\", 2: \"$100-$249\", 3: \"$300+\"},\n",
    "    \"form_c\": {0: \"Winter\", 1: \"Spring\", 2: \"Summer\", 3: \"Fall\"},\n",
    "    \"form_f\": {0: \"Beach\", 1: \"Adventure\", 2: \"Nature\", 3: \"Culture\", 4: \"Nightlife\", 5: \"History\", 6: \"Shopping\", 7: \"Cuisine\"},\n",
    "    \"form_g\": {0: \"Urban\", 1: \"Rural\", 2: \"Sea\", 3: \"Mountain\", 4: \"Lake\", 5: \"Desert\", 6: \"Plains\", 7: \"Jungle\"},\n",
    "    \"form_h\": {0: \"Chill & Relaxed\", 1: \"Balanced\", 2: \"Active\"},\n",
    "    \"form_i\": {0: \"Very Safety Conscious\", 1: \"Balanced\", 2: \"Ready for Anything\"},\n",
    "    \"form_j\": {0: \"Off the Beaten Path\", 1: \"Classic Spot\", 2: \"Mainstream & Trendy\"},\n",
    "    \"form_r\": {0: \"Anywhere\", 1: \"Specific Regions\"},\n",
    "}\n",
    "\n",
    "form_rr_mapping = {\n",
    "    \"e\": \"Europe\", \"n\": \"N. America\", \"c\": \"Caribbean\", \"a\": \"Asia\",\n",
    "    \"s\": \"S. America\", \"m\": \"Mid. East\", \"f\": \"Africa\", \"o\": \"Oceania\"\n",
    "}\n",
    "\n",
    "#function to decode general form responses\n",
    "def decode_form_response(value, mapping):\n",
    "    if pd.isna(value):\n",
    "        return None  # Handle missing values\n",
    "    \n",
    "    #if the value is already a list, decode each item\n",
    "    if isinstance(value, list):\n",
    "        return [mapping.get(int(i), f\"Unknown({i})\") for i in value]\n",
    "    \n",
    "    #if value is a string that looks like a list \n",
    "    if isinstance(value, str) and value.startswith(\"[\"):\n",
    "        try:\n",
    "            indices = ast.literal_eval(value)\n",
    "            return [mapping.get(int(i), f\"Unknown({i})\") for i in indices]\n",
    "        except (ValueError, SyntaxError): \n",
    "            return f\"Invalid list format: {value}\"\n",
    "    \n",
    "    try:\n",
    "        return mapping.get(int(value), f\"Unknown({value})\")\n",
    "    except (ValueError, TypeError): \n",
    "        return f\"Invalid value: {value}\"\n",
    "\n",
    "#function to decode form_rr separately\n",
    "def decode_form_rr(value, mapping):\n",
    "    if pd.isna(value):\n",
    "        return None  # Handle missing values\n",
    "    \n",
    "    #if it's a string representing multiple values (e.g., \"[n,s]\")\n",
    "    if isinstance(value, str) and value.startswith(\"[\"):\n",
    "        try:\n",
    "            indices = ast.literal_eval(value)\n",
    "            return [mapping.get(i, f\"Unknown({i})\") for i in indices]\n",
    "        except (ValueError, SyntaxError):  # Handle parsing errors\n",
    "            return f\"Invalid list format: {value}\"\n",
    "    \n",
    "    return mapping.get(value, f\"Unknown({value})\")\n",
    "\n",
    "#apply decoding to form columns (excluding form_rr)\n",
    "for column, mapping in form_mappings.items():\n",
    "    if column in df.columns:\n",
    "        df[column + \"_decoded\"] = df[column].apply(lambda x: decode_form_response(x, mapping))\n",
    "\n",
    "#apply decoding to form_rr separately\n",
    "if \"form_rr\" in df.columns:\n",
    "    df[\"form_rr_decoded\"] = df[\"form_rr\"].apply(lambda x: decode_form_rr(x, form_rr_mapping))\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359289c3-29e8-4a6c-b696-50a258409353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"decoded_data.csv\", index=False)\n",
    "df = pd.read_csv(\"decoded_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8842bebb-7291-42f9-b786-152bf234afe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sithu\\AppData\\Local\\Temp\\ipykernel_19812\\369500190.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"Unknown\", inplace=True)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.01 GiB for an array with shape (80300, 80301) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#handling missing values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[1;32m----> 4\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:224\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    214\u001b[0m         dummy \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    215\u001b[0m             col[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    216\u001b[0m             prefix\u001b[38;5;241m=\u001b[39mpre,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    222\u001b[0m         )\n\u001b[0;32m    223\u001b[0m         with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    227\u001b[0m         data,\n\u001b[0;32m    228\u001b[0m         prefix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    234\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     mgrs \u001b[38;5;241m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mgrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs_indexers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mgrs_indexers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnblocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[0;32m    220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    221\u001b[0m             axes[i],\n\u001b[0;32m    222\u001b[0m             indexers[i],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m             use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[1;32m--> 230\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    232\u001b[0m     new_mgrs\u001b[38;5;241m.\u001b[39mappend(mgr)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m, deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[0;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.01 GiB for an array with shape (80300, 80301) and data type bool"
     ]
    }
   ],
   "source": [
    "#handling missing values\n",
    "df.fillna(\"Unknown\", inplace=True) \n",
    "\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84d7c52b-e6d0-4e7e-8e9a-8fef07c444f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id                          form_f  \\\n",
      "0  22871c2cb8ee11ec9a19fefb5d5b7ead            ['0', '1', '2', '7']   \n",
      "1  89b7022ab8f011ec9a19fefb5d5b7ead  ['0', '3', '4', '5', '6', '7']   \n",
      "2  c64f6c36b8f011ec9a19fefb5d5b7ead       ['0', '1', '3', '4', '7']   \n",
      "3  1eb6079ab8f111ec9a19fefb5d5b7ead                           ['7']   \n",
      "4  285e9852b8f111ec9a19fefb5d5b7ead                           ['2']   \n",
      "\n",
      "                 form_g form_k form_rr  \\\n",
      "0       ['0', '2', '4']  ['2']     NaN   \n",
      "1  ['0', '1', '2', '4']  ['1']     NaN   \n",
      "2  ['0', '2', '4', '7']  ['0']     NaN   \n",
      "3                 ['4']  ['1']     NaN   \n",
      "4       ['2', '3', '4']  ['0']     NaN   \n",
      "\n",
      "                                          yes_swipes  \\\n",
      "0  ['Dubai, United Arab Emirates', 'Geneva, Switz...   \n",
      "1           ['Luxor, Egypt', 'Utrecht, Netherlands']   \n",
      "2  ['Mexico City, Mexico', 'Faro, Portugal', 'McC...   \n",
      "3  ['Versailles, France', 'Copenhagen, Denmark', ...   \n",
      "4  ['Big Sky, Montana, United States', 'Naxos, Gr...   \n",
      "\n",
      "                                           no_swipes            maybe_swipes  \\\n",
      "0  ['Santa Fe, New Mexico, United States', 'Edinb...                      []   \n",
      "1  ['Montreal, Canada', 'Palm Springs, California...                      []   \n",
      "2  ['Baltimore, Maryland, United States', 'Irvine...  ['Postojna, Slovenia']   \n",
      "3  ['Brisbane, Australia', 'San Antonio, Texas, U...                      []   \n",
      "4  ['Salt Lake City, Utah, United States', 'Versa...                      []   \n",
      "\n",
      "   Model  Retrieval  ...  form_g_decoded_['Urban', 'Sea']  \\\n",
      "0     -1         -1  ...                            False   \n",
      "1     -1         -1  ...                            False   \n",
      "2     -1         -1  ...                            False   \n",
      "3     -1         -1  ...                            False   \n",
      "4     -1         -1  ...                            False   \n",
      "\n",
      "   form_g_decoded_['Urban']  form_h_['1']  form_h_['2']  form_i_['1']  \\\n",
      "0                     False          True         False          True   \n",
      "1                     False          True         False          True   \n",
      "2                     False          True         False          True   \n",
      "3                     False          True         False         False   \n",
      "4                     False         False         False          True   \n",
      "\n",
      "   form_i_['2']  form_j_['0']  form_j_['1']  form_j_['2']  form_r_['1']  \n",
      "0         False         False          True         False         False  \n",
      "1         False         False          True         False         False  \n",
      "2         False         False          True         False         False  \n",
      "3          True         False          True         False         False  \n",
      "4         False          True         False         False         False  \n",
      "\n",
      "[5 rows x 576 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load your dataset\n",
    "df = pd.read_csv(\"decoded_data.csv\")\n",
    "\n",
    "#categorical columns to apply One-Hot Encoding\n",
    "categorical_columns = [\"form_a\", \"form_b\", \"form_c\", \"form_f_decoded\", \"form_g_decoded\", \n",
    "                        \"form_h\", \"form_i\", \"form_j\", \"form_r\"]\n",
    "\n",
    "#apply One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "df_encoded.to_csv(\"encoded_data.csv\", index=False)\n",
    "\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "694f31ca-a460-44b1-8aa2-6894c4580c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sithu\\AppData\\Local\\Temp\\ipykernel_19812\\2687677536.py:2: DtypeWarning: Columns (26,27,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"encoded_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id                     form_f  \\\n",
      "77479  cd3dc0b6ca7811ed92b90a6e5a3aa765  ['0', '3', '4', '6', '7']   \n",
      "20044  0fccaf90b93211ec8d48727d020e48c7            ['1', '2', '5']   \n",
      "47213  58aeeee4b99111ec82ab5a02b93b35bb                 ['5', '7']   \n",
      "21404  0660d77eb93711ec8d48727d020e48c7       ['0', '3', '4', '5']   \n",
      "76072  db8ca680c02f11edbb7622d2271a10f0            ['1', '2', '3']   \n",
      "\n",
      "                               form_g form_k form_rr  \\\n",
      "77479                 ['0', '2', '4']  ['2']   ['a']   \n",
      "20044                 ['1', '3', '4']  ['1']     NaN   \n",
      "47213                      ['1', '4']  ['1']     NaN   \n",
      "21404                      ['0', '2']  ['1']     NaN   \n",
      "76072  ['0', '1', '2', '3', '4', '7']  ['1']     NaN   \n",
      "\n",
      "                             yes_swipes  \\\n",
      "77479  ['Tokyo, Japan', 'Kyoto, Japan']   \n",
      "20044                                []   \n",
      "47213          ['Newcastle, Australia']   \n",
      "21404                                []   \n",
      "76072                                []   \n",
      "\n",
      "                                               no_swipes maybe_swipes  Model  \\\n",
      "77479  ['Antalya, Turkey', 'Dahshur, Egypt', 'Phu Quo...           []      0   \n",
      "20044                                                 []           []     -1   \n",
      "47213  ['Nassau, Bahamas', 'Dubai, United Arab Emirat...           []     -1   \n",
      "21404                                                 []           []     -1   \n",
      "76072                                                 []           []      3   \n",
      "\n",
      "       Retrieval  ...  form_g_decoded_['Urban', 'Sea']  \\\n",
      "77479          0  ...                            False   \n",
      "20044         -1  ...                            False   \n",
      "47213         -1  ...                            False   \n",
      "21404         -1  ...                             True   \n",
      "76072          1  ...                            False   \n",
      "\n",
      "       form_g_decoded_['Urban']  form_h_['1']  form_h_['2']  form_i_['1']  \\\n",
      "77479                     False          True         False         False   \n",
      "20044                     False         False         False          True   \n",
      "47213                     False          True         False          True   \n",
      "21404                     False          True         False         False   \n",
      "76072                     False          True         False         False   \n",
      "\n",
      "       form_i_['2']  form_j_['0']  form_j_['1']  form_j_['2']  form_r_['1']  \n",
      "77479         False         False         False         False          True  \n",
      "20044         False         False          True         False         False  \n",
      "47213         False         False          True         False         False  \n",
      "21404         False         False         False          True         False  \n",
      "76072         False         False         False         False         False  \n",
      "\n",
      "[5 rows x 576 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"encoded_data.csv\")\n",
    "\n",
    "#sample 10,000 rows from the dataset\n",
    "df_sampled = df.sample(n=10000, random_state=1026)  \n",
    "\n",
    "df_sampled.to_csv(\"sampled_data1.csv\", index=False)\n",
    "\n",
    "print(df_sampled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7634628a-95a2-49a5-8484-a6c6c32d04ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'form_f', 'form_g', 'form_k', 'form_rr', 'yes_swipes',\n",
      "       'no_swipes', 'maybe_swipes', 'Model', 'Retrieval',\n",
      "       ...\n",
      "       'form_g_decoded_['Urban', 'Sea']', 'form_g_decoded_['Urban']',\n",
      "       'form_h_['1']', 'form_h_['2']', 'form_i_['1']', 'form_i_['2']',\n",
      "       'form_j_['0']', 'form_j_['1']', 'form_j_['2']', 'form_r_['1']'],\n",
      "      dtype='object', length=576)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3204c7e9-c3ae-4aab-bce7-49ac3e3a0444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (7000, 576)\n",
      "Validation data shape: (1000, 576)\n",
      "Test data shape: (2000, 576)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split into 80% training and 20% testing\n",
    "train_data, test_data = train_test_split(df_sampled, test_size=0.2, random_state=1026)\n",
    "\n",
    "#split the training data into 80% training and 20% validation, which is 10% of the original data\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.125, random_state=1026)\n",
    "\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "854eecaf-6346-44e8-ac36-37e78a196601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '7551cfd6b9e511eca62e926813093b27'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:537\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    512\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:272\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    273\u001b[0m     delayed(_fit_estimator)(\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y[:, i], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit\n\u001b[0;32m    275\u001b[0m     )\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    277\u001b[0m )\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\multioutput.py:61\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     59\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    364\u001b[0m     X,\n\u001b[0;32m    365\u001b[0m     y,\n\u001b[0;32m    366\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    367\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    368\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    369\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    370\u001b[0m )\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1264\u001b[0m     X,\n\u001b[0;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1266\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1267\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1268\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1269\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1270\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1271\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1272\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1273\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1274\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1275\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1277\u001b[0m )\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    920\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[1;32m--> 921\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(new_dtype)\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    923\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '7551cfd6b9e511eca62e926813093b27'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"sampled_data1.csv\")\n",
    "\n",
    "#encode target labels (rec_0 to rec_4)\n",
    "label_encoders = {}\n",
    "for col in [\"Rec_0\", \"Rec_1\", \"Rec_2\", \"Rec_3\", \"Rec_4\"]:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "#select feature columns (excluding rec_0 to rec_4)\n",
    "feature_columns = [col for col in df.columns if col not in [\"Rec_0\", \"Rec_1\", \"Rec_2\", \"Rec_3\", \"Rec_4\"]]\n",
    "X = df[feature_columns]\n",
    "y = df[[\"Rec_0\", \"Rec_1\", \"Rec_2\", \"Rec_3\", \"Rec_4\"]]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize RandomForest with MultiOutputClassifier\n",
    "base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model = MultiOutputClassifier(base_model)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = np.mean([accuracy_score(y_test[col], y_pred[:, i]) for i, col in enumerate(y.columns)])\n",
    "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Generate classification reports for each recommendation column\n",
    "for i, col in enumerate(y.columns):\n",
    "    print(f\"Classification Report for {col}:\")\n",
    "    print(classification_report(y_test[col], y_pred[:, i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1af62f8b-1dc5-4df7-bcd7-12518dbdb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sithu\\AppData\\Local\\Temp\\ipykernel_19812\\763492889.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"Unknown\", inplace=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_test)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Generate the classification report with the correct labels\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred, labels\u001b[38;5;241m=\u001b[39mclass_labels, target_names\u001b[38;5;241m=\u001b[39mclass_labels))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"sampled_data1.csv\")\n",
    "\n",
    "# Fill missing values with \"Unknown\" (already handled earlier)\n",
    "df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Assuming 'Rec_0' is the target variable we want to predict\n",
    "# Extract features and target column\n",
    "features = df.drop(columns=['Rec_0', 'id'])  # Drop 'Rec_0' and 'id' columns\n",
    "target = df['Rec_0']  # Target is 'Rec_0'\n",
    "\n",
    "# Apply one-hot encoding to the features if not done already\n",
    "features_encoded = pd.get_dummies(features, drop_first=True)\n",
    "\n",
    "# Encoding the target variable (Rec_0) as it might have string values\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Split the data into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target_encoded, test_size=0.2, random_state=1026)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=1026)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Get the unique classes from the label encoder\n",
    "unique_classes = label_encoder.classes_\n",
    "\n",
    "# Ensure that y_test is a NumPy array\n",
    "class_labels = np.unique(y_test)\n",
    "\n",
    "# Generate the classification report with the correct labels\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, labels=class_labels, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e0ee0-656a-4d32-9f8b-949ba2663fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "\n",
    "# Set labels for the axes\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708c3c6-748b-4d9b-8d55-572bba06cb79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
